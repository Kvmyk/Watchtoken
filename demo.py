#!/usr/bin/env python3
"""
Demo script dla biblioteki WatchToken.
Pokazuje praktyczne przypadki uÅ¼ycia w rzeczywistych scenariuszach.
"""

from watchtoken import TokenCounter, FileLogger
from watchtoken.utils import get_model_summary, calculate_batch_cost
import json


def main():
    """GÅ‚Ã³wna demonstracja funkcjonalnoÅ›ci WatchToken."""
    print("ğŸ• WatchToken Demo - Praktyczne zastosowania")
    print("=" * 50)
    
    # 1. Analiza kosztÃ³w dla rÃ³Å¼nych zadaÅ„
    analyze_task_costs()
    
    # 2. Optymalizacja promptÃ³w
    optimize_prompts()
    
    # 3. Monitorowanie budÅ¼etu
    budget_monitoring()
    
    # 4. PorÃ³wnanie modeli dla konkretnego zadania
    model_selection()


def analyze_task_costs():
    """Analiza kosztÃ³w dla typowych zadaÅ„ LLM."""
    print("\nğŸ“Š Analiza kosztÃ³w typowych zadaÅ„")
    print("-" * 30)
    
    tasks = {
        "TÅ‚umaczenie": {
            "prompt": "PrzetÅ‚umacz nastÄ™pujÄ…cy tekst na jÄ™zyk angielski: 'Sztuczna inteligencja rewolucjonizuje sposÃ³b, w jaki pracujemy i Å¼yjemy.'",
            "output_tokens": 30
        },
        "Streszczenie": {
            "prompt": "Napisz streszczenie nastÄ™pujÄ…cego artykuÅ‚u w 3 zdaniach: [artykuÅ‚ o AI o dÅ‚ugoÅ›ci 1000 sÅ‚Ã³w]",
            "output_tokens": 100
        },
        "Generowanie kodu": {
            "prompt": "Napisz funkcjÄ™ Python, ktÃ³ra sortuje listÄ™ sÅ‚ownikÃ³w wedÅ‚ug wybranego klucza, z obsÅ‚ugÄ… bÅ‚Ä™dÃ³w.",
            "output_tokens": 200
        },
        "Analiza sentymentu": {
            "prompt": "Przeanalizuj sentyment nastÄ™pujÄ…cych 10 opinii klientÃ³w i podsumuj wyniki.",
            "output_tokens": 150
        }
    }
    
    tc = TokenCounter("gpt-4-turbo")
    
    print(f"{'Zadanie':<20} {'Input tokens':<12} {'Output tokens':<13} {'Koszt':<10}")
    print("-" * 60)
    
    total_cost = 0
    for task_name, task_data in tasks.items():
        input_tokens = tc.count(task_data["prompt"])
        cost = tc.estimate_cost(task_data["prompt"], task_data["output_tokens"])
        total_cost += cost
        
        print(f"{task_name:<20} {input_tokens:<12} {task_data['output_tokens']:<13} ${cost:<9.6f}")
    
    print("-" * 60)
    print(f"{'RAZEM':<20} {'':<12} {'':<13} ${total_cost:<9.6f}")


def optimize_prompts():
    """Demonstracja optymalizacji promptÃ³w."""
    print("\nğŸ”§ Optymalizacja promptÃ³w")
    print("-" * 25)
    
    # RÃ³Å¼ne wersje tego samego zadania
    versions = {
        "PeÅ‚na wersja": """
        ProszÄ™ o szczegÃ³Å‚owÄ… analizÄ™ nastÄ™pujÄ…cego fragmentu kodu Python, 
        uwzglÄ™dniajÄ…c nastÄ™pujÄ…ce aspekty:
        1. CzytelnoÅ›Ä‡ i styl kodowania
        2. WydajnoÅ›Ä‡ algorytmiczna  
        3. MoÅ¼liwe optymalizacje
        4. Potencjalne bÅ‚Ä™dy lub problemy
        5. ZgodnoÅ›Ä‡ z PEP 8
        6. Sugestie ulepszeÅ„
        
        Kod do analizy:
        def sort_list(data):
            return sorted(data)
        """,
        
        "Zoptymalizowana": """
        Przeanalizuj kod Python pod kÄ…tem: czytelnoÅ›ci, wydajnoÅ›ci, bÅ‚Ä™dÃ³w, PEP 8 i ulepszeÅ„:
        
        def sort_list(data):
            return sorted(data)
        """
    }
    
    tc = TokenCounter("gpt-4-turbo")
    
    print("PorÃ³wnanie wersji promptu:")
    for version, prompt in versions.items():
        tokens = tc.count(prompt.strip())
        cost = tc.estimate_cost(prompt.strip(), output_tokens=300)
        
        print(f"\n{version}:")
        print(f"  Tokeny: {tokens}")
        print(f"  Koszt: ${cost:.6f}")
    
    # Obliczenie oszczÄ™dnoÅ›ci
    full_cost = tc.estimate_cost(versions["PeÅ‚na wersja"].strip(), output_tokens=300)
    opt_cost = tc.estimate_cost(versions["Zoptymalizowana"].strip(), output_tokens=300)
    savings = full_cost - opt_cost
    savings_percent = (savings / full_cost) * 100
    
    print(f"\nğŸ’° OszczÄ™dnoÅ›ci: ${savings:.6f} ({savings_percent:.1f}%)")


def budget_monitoring():
    """Demonstracja monitorowania budÅ¼etu."""
    print("\nğŸ’° Monitorowanie budÅ¼etu")
    print("-" * 22)
    
    daily_budget = 5.00  # $5 dziennie
    current_usage = 0.0
    
    # Symulacja operacji w ciÄ…gu dnia
    operations = [
        ("Analiza dokumentu prawnego", "gpt-4-turbo", 500, 1000),
        ("TÅ‚umaczenie artykuÅ‚u", "gpt-3.5-turbo", 300, 400),
        ("Generowanie opisÃ³w produktÃ³w", "gpt-3.5-turbo", 200, 600),
        ("Odpowiedzi na pytania klientÃ³w", "gpt-3.5-turbo", 150, 200),
        ("Podsumowanie raportu", "claude-3-sonnet", 400, 300),
    ]
    
    logger = FileLogger("budget_log.json")
    
    print(f"Dzienny budÅ¼et: ${daily_budget:.2f}")
    print("\nOperacje:")
    
    for operation, model, input_est, output_est in operations:
        tc = TokenCounter(model, logger=logger)
        
        # Symulacja prompt (uÅ¼ywamy estymacji tokenÃ³w)
        mock_prompt = "x" * (input_est * 4)  # ~4 znaki na token
        cost = tc.estimate_cost(mock_prompt, output_tokens=output_est)
        
        current_usage += cost
        remaining = daily_budget - current_usage
        
        status = "âœ…" if remaining > 0 else "âŒ"
        
        print(f"  {status} {operation[:30]:<30} ({model}) ${cost:.4f}")
        print(f"     UÅ¼yto: ${current_usage:.4f} | PozostaÅ‚o: ${remaining:.4f}")
        
        if remaining <= 0:
            print(f"     âš ï¸ Przekroczono budÅ¼et dzienny!")
            break
        elif remaining < 1.0:
            print(f"     âš ï¸ MaÅ‚o pozostaÅ‚o do limitu!")


def model_selection():
    """Pomoc w wyborze najlepszego modelu dla zadania."""
    print("\nğŸ¯ WybÃ³r modelu dla zadania")
    print("-" * 27)
    
    task_prompt = "Napisz szczegÃ³Å‚owÄ… recenzjÄ™ filmu 'Inception' uwzglÄ™dniajÄ…c fabuÅ‚Ä™, reÅ¼yseriÄ™, muzykÄ™ i efekty specjalne."
    expected_output = 800  # tokenÃ³w
    
    models_to_test = ["gpt-3.5-turbo", "gpt-4-turbo", "claude-3-sonnet", "claude-3-haiku"]
    
    print(f"Zadanie: Recenzja filmu (szacowane {expected_output} tokenÃ³w wyjÅ›cia)")
    print(f"{'Model':<20} {'Input tokens':<12} {'Koszt':<10} {'Koszt/1K out':<12}")
    print("-" * 60)
    
    results = []
    for model in models_to_test:
        try:
            tc = TokenCounter(model)
            input_tokens = tc.count(task_prompt)
            cost = tc.estimate_cost(task_prompt, output_tokens=expected_output)
            
            # Koszt na 1000 tokenÃ³w wyjÅ›cia (dla porÃ³wnania)
            cost_per_1k = (cost / (input_tokens + expected_output)) * 1000
            
            results.append({
                "model": model,
                "input_tokens": input_tokens,
                "cost": cost,
                "cost_per_1k": cost_per_1k
            })
            
            print(f"{model:<20} {input_tokens:<12} ${cost:<9.6f} ${cost_per_1k:<11.6f}")
            
        except Exception as e:
            print(f"{model:<20} {'Error:':<12} {str(e)[:20]}")
    
    # Rekomendacja
    if results:
        cheapest = min(results, key=lambda x: x["cost"])
        print(f"\nğŸ’¡ Rekomendacja: {cheapest['model']} (najtaÅ„szy: ${cheapest['cost']:.6f})")


def export_model_comparison():
    """Export porÃ³wnania modeli do JSON."""
    print("\nğŸ“„ Export danych o modelach")
    print("-" * 26)
    
    summary = get_model_summary()
    
    # Zapis do pliku
    with open("models_comparison.json", "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print("âœ… Dane o modelach wyeksportowane do 'models_comparison.json'")
    print(f"Znaleziono {len(summary)} modeli")


if __name__ == "__main__":
    try:
        main()
        export_model_comparison()
        
        print("\n" + "=" * 50)
        print("âœ… Demo zakoÅ„czone pomyÅ›lnie!")
        print("\nPliki utworzone:")
        print("  - token_usage.log (podstawowe logowanie)")
        print("  - budget_log.json (monitorowanie budÅ¼etu)")
        print("  - models_comparison.json (porÃ³wnanie modeli)")
        
    except Exception as e:
        print(f"\nâŒ BÅ‚Ä…d podczas demo: {e}")
        import traceback
        traceback.print_exc()
